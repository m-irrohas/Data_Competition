{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第一回コンペまとめ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "コンペでやったことまとめます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 初めに\n",
    "- EDA\n",
    "    - 分析\n",
    "    - いろいろ試してみる\n",
    "    - 特徴量選択\n",
    "    \n",
    "- 試した手法\n",
    "    - モデル選択\n",
    "    - emsemble\n",
    "    - stacking\n",
    "    - パラメータチューニング\n",
    "\n",
    "- その他・感想含め"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## はじめに\n",
    "\n",
    "・ PUBGとは(軽く)\n",
    "\n",
    "PUBGとは，FPS・TPS式のサバイバルゲームです。最大(かどうかは忘れたけど)100人のプレイヤーが無人島でバトルロイヤル方式で戦って，最後まで生き残りをかけて争います。最後まで生き残ったら勝利すなわち__ドン勝__です。つまりwinPlacePerc=1.0⇔ドン勝です。スタートは上空で，地上に降りた人たちが武器や車を使いこなします。\n",
    "\n",
    "・コンペについて\n",
    "\n",
    "今回予測するのは，あるプレイヤーのドン勝率です。与えられたデータの説明変数として，そのプレイヤーのkill数や移動距離や回復量などがあります。ただし，注意するのはこのパラメータは試合終了時です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA\n",
    "一番時間使いました。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分析\n",
    "とりあえず，可視化してみるのがいいと思います。各変数の説明変数の相関係数を図で示します。\n",
    "<img src=\"./image/corr.png\">\n",
    "これをもとに相関係数が高い奴の片方を除去したり，あるいは相関係数が低いやつの交差項(除算なり乗算なり)を求める指標にします。\n",
    "\n",
    "\n",
    "### いろいろ試してみる\n",
    "\n",
    "こればっかりは試してみるしかありません。今回僕が試した方法として，\n",
    "1. 交差項を生成\n",
    "2. Target Encoding\n",
    "3. ドメイン知識の利用\n",
    "です。交差項の生成については，諸々の特徴量をかけたり割ったりして試行錯誤します。他に，sklearnの標準モジュールに`PolynomialFeatures`という、すべての特徴量の2次の交差項を求めてくれる便利なものを使いましたが，あまりうまくいかなかった印象でした。あとは，相関係数の低い特徴量同士の交差項を300個生成したりしましたが，こちらもあまり精度が伸びなかった印象です。\n",
    "\n",
    "Target Encodingはカテゴリタイプの特徴量にたいして有効です。今回の場合はmatchTypeです。これはNLPでありがちなワンホットベクターを生成してくれます。カテゴリタイプはこれ一択だと思います。今回，matchTypeにはsoloやduoだけでなく，solo-fppやsquad-tppなど細かく16種類あります。そこで，考えた案として，それぞれのカテゴリをsolo，duo，squad等の情報に圧縮するか，そのまま16カテゴリで用いるかです。over-fittingの可能性も考慮すると，データの情報量が多ければ多いほどいいというわけでもないので，これは実験するしかないです。今回はそのまま用いた(ような気がします)。\n",
    "\n",
    "ドメイン知識とはちょっとしたメタ的な情報です。例えば，FPSゲーでありがちなKDA(今回は死んだら終わりなのでD=1だったり)，ヘッドショット率などがこれに当てはまります。あとは，今回は同一試合で100人なので，matchTypeでグループ化するなどすると有効だったような気がします。扱った特徴量についてはコードを参照してください。\n",
    "\n",
    "### 特徴量選択\n",
    "\n",
    "特徴量は絞ったほうがいいと思います。理由としては，単純に精度が上がるというのと，計算時間が早まるからです。具体的な手法として，\n",
    "1. 相関が高い特徴量のうち片方を削除\n",
    "2. Null Importance\n",
    "3. SHAP(知らなかった)\n",
    "4. feature importanceの利用\n",
    "\n",
    "とかがあります。\n",
    "今回僕は1と4を使用しました。例えば，LightGBMのfeature_importanceというものを用いると，\n",
    "<img src=\"./image/feature_imp.png\">\n",
    "こんな感じで出力できます。(ぐっちゃぐちゃですいません。)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 試した手法\n",
    "\n",
    "### モデル選択\n",
    "ここから具体的なモデル構築になるのですが，試したモデルとして\n",
    "1. 決定木\n",
    "2. ランダムフォレスト\n",
    "3. 勾配ブースティング\n",
    "4. ~~NN~~(時間の都合で試せず)\n",
    "\n",
    "をそれぞれ試しました。勾配ブースティングが最も精度が出てましたけど，アンサンブル・スタッキングも考慮してまだ残しておきます。\n",
    "\n",
    "### ensemble\n",
    "アンサンブル学習は，複数の学習器を組み合わせて1つの学習器を用いる方法です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
